{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e2f9c2-8151-485e-bd30-6c7648d849c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c05d7d2-efca-4eba-9cf8-72738cfad7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'compaign_amazon.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompaign_amazon.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'compaign_amazon.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('compaign_amazon.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4201b7-dc0d-48a9-a785-c226d9108a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebeeae-0db9-43e3-abd7-1968db74f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771451e-744d-469b-bb45-1c58e9cd21e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97294f4f-45d1-465a-bc92-290e633b6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd5eb6-7e1b-4cbf-8267-89b35881908f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238e3fd-51f2-4593-9629-01a3ed6fd6a8",
   "metadata": {},
   "source": [
    "# basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1c49e-3231-4058-9f77-28e94811173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e359ee-8394-4aaa-b954-11c260edd8d1",
   "metadata": {},
   "source": [
    "###  No any missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57bd4f-02f0-4df3-957e-eead4c44f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1791985-3329-4e2a-aa92-28a528827afa",
   "metadata": {},
   "source": [
    "### no any duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518b2e9-db84-411f-a4fb-020114af5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4758ec0-afbd-4241-8aa2-d298f2d2e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e8ca7-cc57-458d-833e-9ac344a21ca5",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bdf17-4020-418d-8ae8-b197362cf77e",
   "metadata": {},
   "source": [
    "##### no any null values\n",
    "##### total memory usage = 75 KB\n",
    "##### Total 19 columns and 500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2aace-6eff-4873-96a3-d6283d02d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()  # statistical information of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4227ce-56a3-41f6-8985-5ec2d22ba3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = \"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d2466-d6ea-4cab-9c8e-0a0363d6500e",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccedb7-c479-4ddb-978c-72ff76b9846f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,50))\n",
    "plot = 1\n",
    "\n",
    "for i in df:\n",
    "    if plot <= 20:\n",
    "        plt.subplot(10,2,plot)\n",
    "        sns.histplot(df[i],kde=True)\n",
    "        # plt.xlabel(column,fontsize=25)\n",
    "        # plt.ylabel(\"Count\",fontsize=20)\n",
    "        # plt.yticks(fontsize=15)\n",
    "    plot = plot+1\n",
    "plt.tight_layout()  # used for stop to overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdf1ce-af42-4397-aebe-7397f3738f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91043e0e-ae29-4806-9f43-4aa02d57fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Keyword'],kde =True)\n",
    "plt.xticks(fontsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47233727-5a58-435a-add7-d3a1cb5e09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['ACoS_%'],kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d4698-efe9-4dea-9547-6efc513dca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082ded1-7142-4bba-b1eb-328e7f45e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plot = 1\n",
    "\n",
    "# for i in df:\n",
    "#     if plot <= 20:\n",
    "#         plt.subplot(10,2,plot)\n",
    "#         sns.histplot(x=df[i],hue = df['ACoS_%'])\n",
    "#         # plt.xlabel(column,fontsize=25)\n",
    "#         # plt.ylabel(\"Count\",fontsize=20)\n",
    "#         # plt.yticks(fontsize=15)\n",
    "#     plot = plot+1\n",
    "# plt.tight_layout()  # used for stop to overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868214a9-2cd1-4b1f-9885-226e5a7079f0",
   "metadata": {},
   "source": [
    "## multivarite analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388281cd-2ce3-4d29-8722-66073d9fd317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df,height=3, aspect=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4770e5-25a6-47a8-848b-0253c5d15863",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df71bbd-a7ec-4f77-be04-28a3fc8b08dd",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b061e-bc3a-43cc-b45c-ba77e6f44411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fba65-740e-409f-bf60-ce40b99e0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['Impressions', 'Clicks', 'Spend_USD', 'Sales_USD', 'Orders', 'CTR_%', 'CPC_USD', 'Conversion_Rate_%', \n",
    "                       'Revenue_per_Click_USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b86b3b-55fc-437d-933d-f3edd40a1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef26d1-9413-4644-a099-caedad91607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))      # defined size of graph using matplotlib library\n",
    "for i, col in enumerate(continuous_features, 1):   # applied the loop\n",
    "    plt.subplot(3, 3, i)  # create a grid of 2x2 plots\n",
    "    sns.boxplot(x=df[col], color='cyan')   # applied boxplot to detect Outliers\n",
    "    plt.xlabel(col)\n",
    "\n",
    "plt.tight_layout()      # help to stop the overlapping\n",
    "plt.show()    # shows the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6756f5-44be-4438-881a-2ddba43b6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_percentage(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "    return len(outliers) / len(series) * 100  # percentage\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e04338-19e6-4568-8a29-37b1cb2c152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in continuous_features:\n",
    "    pct = outlier_percentage(df[feature])\n",
    "    print(f\"{feature}: {pct:.2f}% outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ff249-f1e4-4493-bfe8-f9c715bf9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['CPC_USD'],kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab3add-6f60-4540-8c0c-9c096ca32d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['CPC_USD'].quantile(0.25)\n",
    "Q3 = df['CPC_USD'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Cap values above upper bound\n",
    "df['CPC_USD'] = np.where(df['CPC_USD'] > upper_bound, upper_bound, df['CPC_USD'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd16808-66d0-4da1-ad91-ab398e6ecb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['CPC_USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c091490-946d-42f8-9d54-67132782160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f51e13-74af-4a8c-8d15-bd44cabbe847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f94153-bb3a-470a-b912-9540be84f0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795b040-4288-419f-aebb-e2cd000042b4",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17985e-a09d-475f-84b5-37e56fd7e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = ['Campaign_Name', 'Ad_Group', 'Match_Type','Keyword'] \n",
    "\n",
    "# Apply One-Hot Encoding in a loop and merge back\n",
    "for col in ohe:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col,dtype=int)  # create dummy variables\n",
    "    df = pd.concat([df, dummies], axis=1)          # join with main DataFrame\n",
    "    df.drop(columns=[col], inplace=True)           # drop original column\n",
    "\n",
    "df.head()                                          # shows the first 4 four rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17322d-6498-4573-8a69-d3675c665f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80823331-2f9b-442e-9572-61d161a8f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f68afe-4d83-45e7-8484-ff331468428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f10ee7-02ff-4116-a627-9830ea41c8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5694014-2bcd-456c-ab6c-c2cd9630af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler    # import MinMaxScaler from sklearn.preprocessing\n",
    "scaler= MinMaxScaler()     # Stored MinMaxscaler in variable named \"scaler\"\n",
    "sc = [\"Impressions\",\"Clicks\",\"ACoS_%\",\"Orders\",\"CTR_%\",\"CPC_USD\",\"Conversion_Rate_%\",\"Revenue_per_Click_USD\",\"Day\",\"Month\",\"Weekday\"]    # stored the Features in a form of list on which scaling is to be applied\n",
    "scaler.fit_transform(df[sc])    \n",
    "df[sc] = scaler.fit_transform(df[sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca199f-8406-4c05-9a3f-4c727b46ee74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f9646-ada8-4532-8ea5-55b4fdafad3f",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800aded-20b5-4571-bd9a-59fb6988a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Sales_USD\",axis = 1) # Define independent variables (all features except target)\n",
    "y = df[\"Sales_USD\"]      # Define dependent variable (target column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0eee64-7a79-4f12-be02-8974365ae3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # split the data traning and testing data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=99)  # Split the dataset into training (80%) and testing (20%) sets with a fixed random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933457b2-e084-4e42-aa15-70fd05a46cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression    # Import Linear Regression model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    " \n",
    "lr = LinearRegression()         # Create Linear Regression object\n",
    "lr.fit(x_train, y_train)    # Train the model on training data\n",
    "\n",
    "y_pred = lr.predict(x_test)  # Predict target values for test set and stored in variable named y_pred\n",
    "y_pred_train = lr.predict(x_train)    # Predict target values for training set and stored in variable named y_pred_train\n",
    "\n",
    "\n",
    "print(\"Training r2_score:\", r2_score(y_train, y_pred_train))\n",
    "print(\"Testing r2_score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"Testing RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"Training RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ebbed-3600-49bd-b154-2e4b1a810164",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac5bad-62c0-4ea9-8793-d4f872201407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor    # Import Decision Tree Regressor model\n",
    "DT = DecisionTreeRegressor()                      # Create a Decision Tree Regressor object\n",
    "DT.fit(x_train,y_train)                           # Train the model on training data\n",
    "y_pred2 = DT.predict(x_test)                       # Predict target values for the test set\n",
    "y_pred2_train = DT.predict(x_train)                # Predict target values for the training set\n",
    "\n",
    "# r2_score\n",
    "print(\"Testing r2_score\",r2_score(y_test,y_pred2)) # Evaluate model performance on test data\n",
    "print(\"Training r2_score\",r2_score(y_train,y_pred2_train)) # Evaluate model performance on training data\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, y_pred2))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, y_pred2_train))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"Testing RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred2)))\n",
    "print(\"Training RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d207df-d4cc-470a-91fc-6cf0283c00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor    # Import Random Forest Regressor model\n",
    "RM = RandomForestRegressor()                          # Create a Random Forest Regressor object\n",
    "RM.fit(x_train,y_train)                               # Train the model on training data\n",
    "y_pred3 = RM.predict(x_test)                          # Predict target values for the test set\n",
    "y_pred3_train = RM.predict(x_train)                   # Predict target values for the training set\n",
    "\n",
    "# r2_score\n",
    "print(\"Testing r2_score\",r2_score(y_test,y_pred3))    # Evaluate model performance on test data\n",
    "print(\"Training r2_score\",r2_score(y_train,y_pred3_train))  # Evaluate model performance on training data\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, y_pred3))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, y_pred3_train))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"Testing RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred3)))\n",
    "print(\"Training RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred3_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a3b71-ad9e-42e4-ac00-9a40913ca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_shuffled = np.random.permutation(y_train)\n",
    "\n",
    "DT.fit(x_train, y_shuffled)\n",
    "y_pred = DT.predict(x_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbe9c7-4fc4-402f-96da-6eed7ce2a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor     # Import Bagging Regressor model\n",
    "BR = BaggingRegressor()                           # Create a Bagging Regressor object\n",
    "BR.fit(x_train,y_train)                           # Train the Bagging model on training data\n",
    "y_pred3 = BR.predict(x_test)                      # Predict target values for the test set\n",
    "y_pred3_train = BR.predict(x_train)               # Predict target values for the training set\n",
    "\n",
    "# r2_score\n",
    "print(\"Testing r2_score\",r2_score(y_test,y_pred3)) # Evaluate model performance (R²) on test data\n",
    "print(\"Training r2_score\",r2_score(y_train,y_pred3_train)) # Evaluate model performance (R²) on training data\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, y_pred3))    # Calculate MSE for test predictions\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, y_pred3_train)) # Calculate MSE for training predictions\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"Testing RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred3)))   # Calculate RMSE for test predictions\n",
    "print(\"Training RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred3_train))) # Calculate RMSE for training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f558bef-399d-41d7-adc1-c36f87a9303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor    \n",
    "GB = GradientBoostingRegressor()\n",
    "GB.fit(x_train,y_train)\n",
    "y_pred4 = GB.predict(x_test)\n",
    "y_pred4_train = GB.predict(x_train)\n",
    "\n",
    "# r2_score\n",
    "\n",
    "print(\"Testing r2_score\",r2_score(y_test,y_pred4))\n",
    "print(\"Training r2_score\",r2_score(y_train,y_pred4_train))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "print(\"Testing MSE:\", mean_squared_error(y_test, y_pred4))    # Calculate MSE for test predictions\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, y_pred4_train)) # Calculate MSE for training predictions\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"Testing RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred4)))   # Calculate RMSE for test predictions\n",
    "print(\"Training RMSE:\", np.sqrt(mean_squared_error(y_train, y_pred4_train))) # Calculate RMSE for training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d069c7-2e10-4f1d-b35a-f36f942941f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lr,open(\"Model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1985f-e96f-460d-86fb-b8005f85d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Folder check karna aur banana\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Ab save karein (Error nahi aayegi)\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "joblib.dump(x.columns.tolist(), \"models/train_columns.pkl\")\n",
    "joblib.dump(lr, \"models/Model.pkl\")\n",
    "\n",
    "print(\"Files saved successfully in 'models' folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcf607-11ab-4cd3-8711-0c1b38393901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
